# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CGb09Yu4rKcTeeiMgw49pgMeNxJ-iVbz
"""

import pandas as pd
import numpy as np

np.random.seed(42)

# -------------------------
# 1. Customer Master
# -------------------------
customers = pd.DataFrame({
    'customer_id': range(1, 101),
    'region': np.random.choice(['North','South','East','West'], 100),
    'credit_days': np.random.choice([30,45,60], 100, p=[0.4,0.4,0.2]),
    'risk_category': np.random.choice(['Low','Medium','High'], 100, p=[0.5,0.3,0.2])
})

# -------------------------
# 2. Sales Invoices (AR)
# -------------------------
invoice_count = 50000
invoice_dates = pd.date_range(start='2023-01-01', periods=invoice_count, freq='H')

sales = pd.DataFrame({
    'invoice_id': range(1, invoice_count+1),
    'invoice_date': np.random.choice(invoice_dates, invoice_count),
    'customer_id': np.random.choice(customers['customer_id'], invoice_count),
    'invoice_amount': np.random.randint(5000, 500000, invoice_count)
})

sales = sales.merge(customers[['customer_id','credit_days']], on='customer_id')
sales['due_date'] = sales['invoice_date'] + pd.to_timedelta(sales['credit_days'], unit='D')

# -------------------------
# 3. Payments (with delays)
# -------------------------
delay = np.random.choice([0,5,10,20,30], invoice_count, p=[0.6,0.15,0.1,0.1,0.05])

payments = sales[['invoice_id','due_date']].copy()
payments['payment_date'] = payments['due_date'] + pd.to_timedelta(delay, unit='D')
payments['payment_amount'] = sales['invoice_amount']

# -------------------------
# 4. Inventory
# -------------------------
inventory = pd.DataFrame({
    'sku_id': range(1, 251),
    'category': np.random.choice(['Food','Personal Care','Home Care'], 250),
    'avg_inventory_value': np.random.randint(1e5, 1e7, 250),
    'annual_cogs': np.random.randint(5e5, 5e7, 250)
})

# -------------------------
# 5. Supplier & AP
# -------------------------
suppliers = pd.DataFrame({
    'supplier_id': range(1, 51),
    'credit_days': np.random.choice([20,30,45], 50)
})

po_count = 30000
po = pd.DataFrame({
    'po_id': range(1, po_count+1),
    'supplier_id': np.random.choice(suppliers['supplier_id'], po_count),
    'po_date': np.random.choice(invoice_dates, po_count),
    'po_amount': np.random.randint(10000, 800000, po_count)
})

po = po.merge(suppliers, on='supplier_id')
po['due_date'] = po['po_date'] + pd.to_timedelta(po['credit_days'], unit='D')
po['payment_date'] = po['due_date'] + pd.to_timedelta(
    np.random.choice([0,5,10], po_count, p=[0.7,0.2,0.1]), unit='D'
)

# -------------------------
# Save for Power BI
# -------------------------
sales.to_csv('sales_invoices.csv', index=False)
payments.to_csv('payments.csv', index=False)
inventory.to_csv('inventory.csv', index=False)
po.to_csv('purchase_orders.csv', index=False)

from google.colab import files
uploaded = files.upload()

import os

os.listdir()

file = "FMCG_Working_Capital_Data.xlsx"   # change if name is different

import pandas as pd

pd.ExcelFile(file)

xls = pd.ExcelFile(file)
print(xls.sheet_names)

customers = pd.read_excel(file, sheet_name="Customer_Master")

customers = pd.read_excel(file, sheet_name=xls.sheet_names[0])
customers.head()

customers = pd.read_excel(file, sheet_name="Customer_Master")
sales = pd.read_excel(file, sheet_name="Sales_Invoices", parse_dates=["invoice_date","due_date"])
payments = pd.read_excel(file, sheet_name="Payments", parse_dates=["payment_date"])
inventory = pd.read_excel(file, sheet_name="Inventory")
suppliers = pd.read_excel(file, sheet_name="Suppliers")
po = pd.read_excel(file, sheet_name="Purchase_Orders", parse_dates=["po_date","due_date","payment_date"])

print(customers.shape)
print(sales.shape)
print(payments.shape)
print(inventory.shape)
print(suppliers.shape)
print(po.shape)

import pandas as pd

file = "FMCG_Working_Capital_Data.xlsx"

customers = pd.read_excel(file, sheet_name="Customer_Master")
sales = pd.read_excel(file, sheet_name="Sales_Invoices", parse_dates=["invoice_date","due_date"])
payments = pd.read_excel(file, sheet_name="Payments", parse_dates=["payment_date"])
inventory = pd.read_excel(file, sheet_name="Inventory")
suppliers = pd.read_excel(file, sheet_name="Suppliers")
po = pd.read_excel(file, sheet_name="Purchase_Orders", parse_dates=["po_date","due_date","payment_date"])

"""Merge AR Tables"""

ar = sales.merge(payments, on="invoice_id", how="left") \
          .merge(customers, on="customer_id", how="left")

"""Create Finance-Derived Fields"""

ar["days_to_collect"] = (ar["payment_date"] - ar["invoice_date"]).dt.days
ar["delay_days"] = (ar["payment_date"] - ar["due_date"]).dt.days
ar["overdue_flag"] = ar["delay_days"].apply(lambda x: 1 if x > 0 else 0)

"""Weighted DSO"""

DSO = (ar["days_to_collect"] * ar["invoice_amount"]).sum() / ar["invoice_amount"].sum()
DSO

"""DSO by Channel and Risk"""

dso_channel = ar.groupby("channel").agg(
    avg_dso=("days_to_collect","mean"),
    overdue_pct=("overdue_flag","mean"),
    receivables=("invoice_amount","sum")
).reset_index()

dso_risk = ar.groupby("risk_category").agg(
    avg_dso=("days_to_collect","mean"),
    overdue_pct=("overdue_flag","mean")
).reset_index()

"""Inventory Analysis

DIO
"""

inventory["avg_inventory"] = (
    inventory["opening_stock_value"] + inventory["closing_stock_value"]
) / 2

inventory["DIO"] = (inventory["avg_inventory"] / inventory["annual_cogs"]) * 365

"""Slow-Moving Inventory Flag (FMCG)"""

inventory["slow_moving_flag"] = inventory["DIO"].apply(lambda x: 1 if x > 90 else 0)

"""Portfolio-Level DIO"""

DIO = inventory["DIO"].mean()
DIO

"""Accounts Payable Analysis - DPO"""

ap = po.merge(suppliers, on="supplier_id", how="left")

"""Actual Days to Pay

Check Current Data Types
"""

ap[["po_date", "payment_date"]].dtypes

"""Explicitly Convert to Datetime"""

ap["po_date"] = pd.to_datetime(ap["po_date"], errors="coerce")
ap["payment_date"] = pd.to_datetime(ap["payment_date"], errors="coerce")

"""Recalculate days_to_pay"""

ap["days_to_pay"] = (ap["payment_date"] - ap["po_date"]).dt.days

"""Handle Missing Dates"""

ap = ap.dropna(subset=["days_to_pay"])

"""Weighted DPO

Inspect po_amount
"""

ap["po_amount"].describe()

"""Force po_amount to Numeric"""

ap["po_amount"] = pd.to_numeric(ap["po_amount"], errors="coerce")

"""Remove Invalid Rows"""

ap = ap.dropna(subset=["po_amount", "days_to_pay"])
ap = ap[ap["po_amount"] > 0]

"""Verify Denominator Is Non-Zero"""

ap["po_amount"].sum()

"""Recalculate Weighted DPO"""

DPO = (ap["days_to_pay"] * ap["po_amount"]).sum() / ap["po_amount"].sum()
DPO

denominator = ap["po_amount"].sum()

DPO = (
    (ap["days_to_pay"] * ap["po_amount"]).sum() / denominator
    if denominator != 0 else None
)

DPO

"""Cash Conversion Cycle (CCC)"""

if DPO is not None:
    CCC = DSO + DIO - DPO
else:
    CCC = None

CCC

"""Create KPI Table"""

ccc_kpis = pd.DataFrame({
    "Metric": ["DSO","DIO","DPO","CCC"],
    "Days": [DSO, DIO, DPO, CCC]
})

ccc_kpis.to_csv("CCC_KPIs.csv", index=False)

model_df.shape

ar[[
    "invoice_amount",
    "credit_days",
    "channel",
    "risk_category",
    "delay_flag"
]].isna().sum()

model_df = ar[
    ar["payment_date"].notna()   # only paid invoices
][[
    "invoice_amount",
    "credit_days",
    "channel",
    "risk_category",
    "delay_flag"
]]

model_df.shape

payments.head()
payments["payment_date"].describe()

ar[["invoice_id", "payment_date"]].head(10)

sales["invoice_id"].nunique()
payments["invoice_id"].nunique()

set(payments["invoice_id"]) - set(sales["invoice_id"])

payments["payment_date"].head()
payments["payment_date"].dtype

payments["payment_date"] = pd.to_datetime(
    payments["payment_date"],
    errors="coerce",
    dayfirst=True
)

payments["payment_date"].notna().sum()

payments_raw = pd.read_excel(
    file,
    sheet_name="Payments",
    dtype=str   # IMPORTANT: read everything as text
)

payments_raw.head(10)
payments_raw.columns

payments_raw = payments_raw.rename(columns={
    "Payment Date": "payment_date"   # adjust to exact name
})

import numpy as np

payments = payments_raw.copy()

payments["payment_date"] = pd.to_datetime(
    payments["invoice_id"]
    .map(
        sales.set_index("invoice_id")["due_date"]
    )
) + pd.to_timedelta(
    np.random.choice([0, 5, 10, 20, 30], size=len(payments)),
    unit="D"
)

payments["payment_date"].notna().sum()

payments["invoice_id"].map(
    sales.set_index("invoice_id")["due_date"]
)

sales["invoice_id"] = sales["invoice_id"].astype(str)
payments_raw["invoice_id"] = payments_raw["invoice_id"].astype(str)

sales["due_date"] = pd.to_datetime(
    sales["due_date"],
    errors="coerce",
    dayfirst=True
)

sales["due_date"].notna().sum()

sales.columns
customers.columns

sales = sales.merge(
    customers[["customer_id", "credit_days"]],
    on="customer_id",
    how="left"
)

sales[["invoice_date", "credit_days"]].head()

sales["credit_days"].notna().sum()

sales["invoice_date"] = pd.to_datetime(
    sales["invoice_date"],
    errors="coerce",
    dayfirst=True
)

sales["credit_days"] = pd.to_numeric(
    sales["credit_days"],
    errors="coerce"
)

sales["due_date"] = sales["invoice_date"] + pd.to_timedelta(
    sales["credit_days"],
    unit="D"
)

sales["due_date"].notna().sum()

sales["invoice_date"].head(10)
sales["invoice_date"].dtype

"""Generate Invoice Dates"""

import numpy as np
import pandas as pd

np.random.seed(42)

sales["invoice_date"] = pd.to_datetime(
    np.random.choice(
        pd.date_range("2023-01-01", "2023-12-31"),
        size=len(sales)
    )
)

sales["invoice_date"].notna().sum()

sales["due_date"] = sales["invoice_date"] + pd.to_timedelta(
    sales["credit_days"],
    unit="D"
)

sales["due_date"].notna().sum()

import numpy as np

payments["invoice_id"] = payments["invoice_id"].astype(str)
sales["invoice_id"] = sales["invoice_id"].astype(str)

payments["payment_date"] = (
    payments["invoice_id"]
    .map(sales.set_index("invoice_id")["due_date"])
    + pd.to_timedelta(
        np.random.choice([0, 5, 10, 20, 30], size=len(payments)),
        unit="D"
    )
)

payments["payment_date"].notna().sum()

ar = sales.merge(
    payments,
    on="invoice_id",
    how="inner"
).merge(
    customers,
    on="customer_id",
    how="left"
)

ar["delay_days"] = (ar["payment_date"] - ar["due_date"]).dt.days
ar["delay_flag"] = (ar["delay_days"] > 0).astype(int)

ar["delay_flag"].value_counts()

"""Step 5

5.1: Prepare the AR Modeling Dataset

5.1.1 Create the Target Variable
"""

ar["delay_flag"] = ar["delay_days"].apply(lambda x: 1 if x > 0 else 0)

ar.columns

ar[["credit_days_x", "credit_days_y"]].head(10)

ar["credit_days"] = ar["credit_days_y"]

ar.columns

"""5.1.2 Select Relevant Predictors"""

model_df = ar[[
    "invoice_amount",
    "credit_days",
    "channel",
    "risk_category",
    "delay_flag"
]].copy()

"""STEP 5.2: Encode Categorical Variables"""

model_df = pd.get_dummies(
    model_df,
    columns=["channel", "risk_category"],
    drop_first=True
)

model_df.shape
model_df["delay_flag"].value_counts()

model_df_encoded = pd.get_dummies(
    model_df,
    columns=["channel", "risk_category"],
    drop_first=True
)

model_df_encoded.head()

"""STEP 5.3: Trainâ€“Test Split"""

from sklearn.model_selection import train_test_split

X = model_df_encoded.drop("delay_flag", axis=1)
y = model_df_encoded["delay_flag"]

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.30,
    random_state=42,
    stratify=y   # IMPORTANT: preserves class balance
)

y_train.value_counts(normalize=True)
y_test.value_counts(normalize=True)

"""STEP 5.4: Train Logistic Regression Model"""

X_train.isna().sum()

model_df = ar[[
    "invoice_amount",
    "credit_days",
    "channel",
    "risk_category",
    "delay_flag"
]].copy()

model_df_encoded = pd.get_dummies(
    model_df,
    columns=["channel", "risk_category"],
    drop_first=True
)

from sklearn.model_selection import train_test_split

X = model_df_encoded.drop("delay_flag", axis=1)
y = model_df_encoded["delay_flag"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

"""Train-Test Split Unchanged"""

from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")

X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

"""Train Logistic Regression"""

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train_imputed, y_train)

"""Model Evaluation"""

from sklearn.metrics import accuracy_score, classification_report

y_pred = log_model.predict(X_test_imputed)

accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))

valid_mask = ~np.isnan(imputer.statistics_)
kept_columns = X_train.columns[valid_mask]

X_train_imputed_df = pd.DataFrame(
    X_train_imputed,
    columns=kept_columns,
    index=X_train.index
)

X_test_imputed_df = pd.DataFrame(
    X_test_imputed,
    columns=kept_columns,
    index=X_test.index
)

coefficients = pd.DataFrame({
    "Feature": kept_columns,
    "Coefficient": log_model.coef_.flatten()
}).sort_values(by="Coefficient", ascending=False)

coefficients

len(kept_columns), len(log_model.coef_.flatten())

"""# **STEP 6: Scenario Simulation & Cash Unlock (Working Capital Optimization)**

### STEP 6.1: Attach Delay Probability to AR Data
"""

X_full = model_df_encoded.drop("delay_flag", axis=1)

X_full_imputed = imputer.transform(X_full)

X_full_imputed_df = pd.DataFrame(
    X_full_imputed,
    columns=kept_columns,
    index=ar.index
)

ar["delay_probability"] = log_model.predict_proba(X_full_imputed_df)[:, 1]

ar["delay_probability"].describe()

ar["delay_probability"].notna().sum() == len(ar)

"""### STEP 6.2: Create Risk Buckets"""

ar["risk_bucket"] = pd.cut(
    ar["delay_probability"],
    bins=[0, 0.3, 0.6, 1],
    labels=["Low Risk", "Medium Risk", "High Risk"]
)

ar["risk_bucket"].value_counts()

"""### STEP 6.3: Baseline DSO"""

DSO_current = (
    ar["delay_days"].clip(lower=0) * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_current

"""### STEP 6.4: Define Credit Policy Rules

| Risk Bucket | Policy Action             |
| ----------- | ------------------------- |
| Low Risk    | No change                 |
| Medium Risk | Reduce credit days by 10% |
| High Risk   | Reduce credit days by 20% |

### STEP 6.5: Apply Optimized Credit Days
"""

ar["optimized_credit_days"] = ar["credit_days"]

ar.loc[ar["risk_bucket"] == "Medium Risk", "optimized_credit_days"] *= 0.90
ar.loc[ar["risk_bucket"] == "High Risk", "optimized_credit_days"] *= 0.80

ar["optimized_credit_days"] = ar["optimized_credit_days"].round()

"""### STEP 6.6: Recompute Due Date & Optimized Delay"""

ar["optimized_due_date"] = ar["invoice_date"] + pd.to_timedelta(
    ar["optimized_credit_days"], unit="D"
)

ar["optimized_delay_days"] = (
    ar["payment_date"] - ar["optimized_due_date"]
).dt.days

ar["optimized_delay_days"] = ar["optimized_delay_days"].clip(lower=0)

"""### Step 6.7 Optimized DSO"""

DSO_optimized = (
    ar["optimized_delay_days"] * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_optimized

"""DSO Reduction"""

DSO_reduction = DSO_current - DSO_optimized
DSO_reduction

annual_sales = ar["invoice_amount"].sum()

cash_released = (annual_sales / 365) * DSO_reduction
cash_released

ar["invoice_amount"].isna().sum()
ar["invoice_amount"].sum()

ar["invoice_amount"].describe()

import numpy as np

np.random.seed(42)

ar["invoice_amount"] = np.random.lognormal(
    mean=8.5,   # controls scale
    sigma=0.6,  # controls spread
    size=len(ar)
).round(0)

ar["invoice_amount"].isna().sum()
ar["invoice_amount"].sum()
ar["invoice_amount"].describe()

ar["delay_days"] = ar["delay_days"].fillna(0)
ar["optimized_delay_days"] = ar["optimized_delay_days"].fillna(0)

DSO_current = (
    ar["delay_days"].clip(lower=0) * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_optimized = (
    ar["optimized_delay_days"].clip(lower=0) * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_current, DSO_optimized

DSO_reduction = DSO_current - DSO_optimized

annual_sales = ar["invoice_amount"].sum()

cash_released = (annual_sales / 365) * DSO_reduction

DSO_reduction, cash_released

"""...."""

ar["delay_days"]

ar["optimized_delay_days"] = ar["delay_days"]

ar.loc[ar["risk_bucket"] == "Medium Risk", "optimized_delay_days"] *= 0.8
ar.loc[ar["risk_bucket"] == "High Risk", "optimized_delay_days"] *= 0.6

ar["optimized_delay_days"] = (
    ar["optimized_delay_days"]
    .round()
    .clip(lower=0)
)

DSO_current = (
    ar["delay_days"] * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_optimized = (
    ar["optimized_delay_days"] * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_current, DSO_optimized

DSO_reduction = DSO_current - DSO_optimized

annual_sales = ar["invoice_amount"].sum()

cash_released = (annual_sales / 365) * DSO_reduction

DSO_reduction, cash_released

"""#Step 7 : Management Insights, Recommendations & Sensitivity Analysis

Sensitivity Analysis

Scenario A: Aggressive Policy

Medium Risk â†’ 30% delay reduction

High Risk â†’ 50% delay reduction
"""

ar["opt_delay_aggressive"] = ar["delay_days"]

ar.loc[ar["risk_bucket"] == "Medium Risk", "opt_delay_aggressive"] *= 0.7
ar.loc[ar["risk_bucket"] == "High Risk", "opt_delay_aggressive"] *= 0.5

ar["opt_delay_aggressive"] = ar["opt_delay_aggressive"].round().clip(lower=0)

DSO_aggressive = (
    ar["opt_delay_aggressive"] * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

DSO_aggressive

"""# BIG DATA SIMULATION

Customer Master
"""

import numpy as np
import pandas as pd

np.random.seed(42)

n_customers = 10000

customers = pd.DataFrame({
    "customer_id": [f"CUST_{i}" for i in range(1, n_customers+1)],
    "region": np.random.choice(["North","South","East","West"], n_customers),
    "channel": np.random.choice(
        ["Kirana","Supermarket","E-Commerce","Specialized"],
        n_customers,
        p=[0.4, 0.25, 0.2, 0.15]
    )
})

customers.head()

"""Assign Credit days"""

credit_map = {
    "Kirana": (10, 25),
    "Supermarket": (30, 45),
    "E-Commerce": (20, 40),
    "Specialized": (45, 60)
}

customers["credit_days"] = customers["channel"].apply(
    lambda x: np.random.randint(*credit_map[x])
)

"""Generate Invoices"""

n_invoices = 150000

ar = pd.DataFrame({
    "invoice_id": [f"INV_{i}" for i in range(1, n_invoices+1)],
    "customer_id": np.random.choice(customers["customer_id"], n_invoices),
    "invoice_date": pd.to_datetime("2023-01-01") +
                    pd.to_timedelta(np.random.randint(0, 365, n_invoices), unit="D"),
})

ar = ar.merge(customers, on="customer_id", how="left")

ar["invoice_amount"] = np.random.lognormal(
    mean=8.7,
    sigma=0.7,
    size=n_invoices
).round(0)

"""Generate PAYMENT BEHAVIOR"""

delay_behavior = {
    "Kirana": (0, 10),
    "Supermarket": (5, 20),
    "E-Commerce": (3, 15),
    "Specialized": (10, 30)
}

ar["delay_days"] = ar["channel"].apply(
    lambda x: max(0, int(np.random.normal(
        loc=delay_behavior[x][1],
        scale=5
    )))
)

"""Create DUE DATE & PAYMENT DATE"""

ar["due_date"] = ar["invoice_date"] + pd.to_timedelta(ar["credit_days"], unit="D")

ar["payment_date"] = ar["due_date"] + pd.to_timedelta(ar["delay_days"], unit="D")

"""Risk Category"""

ar["risk_category"] = pd.cut(
    ar["delay_days"],
    bins=[-1, 5, 15, 30, 999],
    labels=["Low","Medium","High","Critical"]
)

"""Save BIG DATA FILES"""

customers.to_csv("Customers_Big.csv", index=False)
ar.to_csv("AR_Big.csv", index=False)

!ls

from google.colab import files

files.download("AR_Big.csv")
files.download("Customers_Big.csv")

!pip install streamlit pyngrok

import os

if not os.path.exists("AR_Big.csv"):
    st.error("AR_Big.csv not found. Please check file location.")
    st.stop()

ar = pd.read_csv("AR_Big.csv")

import streamlit as st
import pandas as pd

st.set_page_config(page_title="Working Capital Dashboard", layout="wide")

st.title("ðŸ“Š Working Capital Optimization Dashboard")

# Load data
ar = pd.read_csv("AR_Big.csv")

# KPI: Average DSO
avg_dso = (ar["delay_days"] * ar["invoice_amount"]).sum() / ar["invoice_amount"].sum()

st.metric("Average DSO (Days)", round(avg_dso, 2))

# What-if Slider
reduction = st.slider("Delay Reduction (Days)", 0, 15, 5)

ar["optimized_delay_days"] = (ar["delay_days"] - reduction).clip(lower=0)

opt_dso = (
    ar["optimized_delay_days"] * ar["invoice_amount"]
).sum() / ar["invoice_amount"].sum()

st.metric("Optimized DSO (Days)", round(opt_dso, 2))
st.metric("DSO Reduction", round(avg_dso - opt_dso, 2))

# Channel-wise Analysis
st.subheader("Channel-wise Invoice Amount")
st.bar_chart(ar.groupby("channel")["invoice_amount"].sum())

# Data Preview
st.subheader("Accounts Receivable Data")
st.dataframe(ar.head(100))

streamlit
pandas
numpy